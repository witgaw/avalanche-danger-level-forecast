{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avalanche hazard level data exploration and cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import remove\n",
    "import glob\n",
    "\n",
    "from utils.latex import LatexHelpers\n",
    "\n",
    "replacements_log = pd.DataFrame(columns=[\"column name\", \"action\"])\n",
    "\n",
    "# # purge all files in the assets folder to make sure we don't realy on any files that are no longer generated\n",
    "# for p in [\"../tex/assets/tables\", \"../tex/assets/snippets\", \"../tex/assets/figures\"]:\n",
    "#     for f in glob.glob(f\"{p}/*\"):\n",
    "#         remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [SAIS](https://www.sais.gov.uk/) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/50qr5bj563lbm6jm3tks0w400000gn/T/ipykernel_15148/1343415093.py:1: DtypeWarning: Columns (2,3,4,7,8,12,13,21,23,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_sais = pd.read_csv(\"../data/raw/SAIS_Any_snowprofiles_1993-12-20_to_2024-04-13.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>non-null</th>\n",
       "      <th>unique</th>\n",
       "      <th>dtype</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>17453</td>\n",
       "      <td>12045</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>2011-03-06</td>\n",
       "      <td>1993-12-20</td>\n",
       "      <td>2024-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Area</th>\n",
       "      <td>17453</td>\n",
       "      <td>6</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Obs</th>\n",
       "      <td>11402</td>\n",
       "      <td>791</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grid</th>\n",
       "      <td>11291</td>\n",
       "      <td>3557</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alt</th>\n",
       "      <td>17434</td>\n",
       "      <td>683</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>17095</td>\n",
       "      <td>337</td>\n",
       "      <td>float64</td>\n",
       "      <td>97.086107</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>163770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incline</th>\n",
       "      <td>17384</td>\n",
       "      <td>56</td>\n",
       "      <td>float64</td>\n",
       "      <td>17.816498</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>11409</td>\n",
       "      <td>3497</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Air Temp</th>\n",
       "      <td>17389</td>\n",
       "      <td>520</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind Dir</th>\n",
       "      <td>17221</td>\n",
       "      <td>366</td>\n",
       "      <td>float64</td>\n",
       "      <td>199.001638</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wind Speed</th>\n",
       "      <td>17376</td>\n",
       "      <td>107</td>\n",
       "      <td>float64</td>\n",
       "      <td>14.232364</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cloud</th>\n",
       "      <td>17402</td>\n",
       "      <td>38</td>\n",
       "      <td>float64</td>\n",
       "      <td>73.342145</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precip Code</th>\n",
       "      <td>10756</td>\n",
       "      <td>9</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drift</th>\n",
       "      <td>17452</td>\n",
       "      <td>6</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Snow Depth</th>\n",
       "      <td>17194</td>\n",
       "      <td>279</td>\n",
       "      <td>float64</td>\n",
       "      <td>65.267826</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foot Pen</th>\n",
       "      <td>17380</td>\n",
       "      <td>87</td>\n",
       "      <td>float64</td>\n",
       "      <td>1.00784</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>310.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ski Pen</th>\n",
       "      <td>14028</td>\n",
       "      <td>28</td>\n",
       "      <td>float64</td>\n",
       "      <td>0.419447</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rain at 900</th>\n",
       "      <td>17453</td>\n",
       "      <td>3</td>\n",
       "      <td>int64</td>\n",
       "      <td>-11.276056</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summit Air Temp</th>\n",
       "      <td>16253</td>\n",
       "      <td>222</td>\n",
       "      <td>float64</td>\n",
       "      <td>-0.778383</td>\n",
       "      <td>-13.4</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summit Wind Dir</th>\n",
       "      <td>15638</td>\n",
       "      <td>357</td>\n",
       "      <td>float64</td>\n",
       "      <td>123.424287</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Summit Wind Speed</th>\n",
       "      <td>16039</td>\n",
       "      <td>153</td>\n",
       "      <td>float64</td>\n",
       "      <td>17.695243</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Observed aval. hazard</th>\n",
       "      <td>11310</td>\n",
       "      <td>6</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Forecast aval. hazard</th>\n",
       "      <td>11792</td>\n",
       "      <td>6</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avalanche Code</th>\n",
       "      <td>17090</td>\n",
       "      <td>214</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Temp Grad</th>\n",
       "      <td>16811</td>\n",
       "      <td>120</td>\n",
       "      <td>float64</td>\n",
       "      <td>1.225662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Hardness Grad</th>\n",
       "      <td>16886</td>\n",
       "      <td>8</td>\n",
       "      <td>float64</td>\n",
       "      <td>1.310375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Settle</th>\n",
       "      <td>16714</td>\n",
       "      <td>368</td>\n",
       "      <td>float64</td>\n",
       "      <td>149.807227</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow Index</th>\n",
       "      <td>16234</td>\n",
       "      <td>58</td>\n",
       "      <td>float64</td>\n",
       "      <td>-3.78157</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insolation</th>\n",
       "      <td>16480</td>\n",
       "      <td>22</td>\n",
       "      <td>float64</td>\n",
       "      <td>-1.416505</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crystals</th>\n",
       "      <td>15988</td>\n",
       "      <td>11</td>\n",
       "      <td>float64</td>\n",
       "      <td>-6.754128</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wetness</th>\n",
       "      <td>16401</td>\n",
       "      <td>11</td>\n",
       "      <td>float64</td>\n",
       "      <td>-3.9222</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AV Cat</th>\n",
       "      <td>14457</td>\n",
       "      <td>20</td>\n",
       "      <td>float64</td>\n",
       "      <td>-3071.001176</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>8800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Snow Temp</th>\n",
       "      <td>16574</td>\n",
       "      <td>284</td>\n",
       "      <td>float64</td>\n",
       "      <td>-6.091794</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comments</th>\n",
       "      <td>13736</td>\n",
       "      <td>5917</td>\n",
       "      <td>object</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       non-null  unique           dtype         mean  \\\n",
       "Date                      17453   12045  datetime64[ns]   2011-03-06   \n",
       "Area                      17453       6          object          NaN   \n",
       "Obs                       11402     791          object          NaN   \n",
       "Grid                      11291    3557          object          NaN   \n",
       "Alt                       17434     683          object          NaN   \n",
       "Aspect                    17095     337         float64    97.086107   \n",
       "Incline                   17384      56         float64    17.816498   \n",
       "Location                  11409    3497          object          NaN   \n",
       "Air Temp                  17389     520          object          NaN   \n",
       "Wind Dir                  17221     366         float64   199.001638   \n",
       "Wind Speed                17376     107         float64    14.232364   \n",
       "Cloud                     17402      38         float64    73.342145   \n",
       "Precip Code               10756       9          object          NaN   \n",
       "Drift                     17452       6          object          NaN   \n",
       "Total Snow Depth          17194     279         float64    65.267826   \n",
       "Foot Pen                  17380      87         float64      1.00784   \n",
       "Ski Pen                   14028      28         float64     0.419447   \n",
       "Rain at 900               17453       3           int64   -11.276056   \n",
       "Summit Air Temp           16253     222         float64    -0.778383   \n",
       "Summit Wind Dir           15638     357         float64   123.424287   \n",
       "Summit Wind Speed         16039     153         float64    17.695243   \n",
       "Observed aval. hazard     11310       6          object          NaN   \n",
       "Forecast aval. hazard     11792       6          object          NaN   \n",
       "Avalanche Code            17090     214          object          NaN   \n",
       "Max Temp Grad             16811     120         float64     1.225662   \n",
       "Max Hardness Grad         16886       8         float64     1.310375   \n",
       "No Settle                 16714     368         float64   149.807227   \n",
       "Snow Index                16234      58         float64     -3.78157   \n",
       "Insolation                16480      22         float64    -1.416505   \n",
       "Crystals                  15988      11         float64    -6.754128   \n",
       "Wetness                   16401      11         float64      -3.9222   \n",
       "AV Cat                    14457      20         float64 -3071.001176   \n",
       "Snow Temp                 16574     284         float64    -6.091794   \n",
       "Comments                  13736    5917          object          NaN   \n",
       "\n",
       "                              min         max  \n",
       "Date                   1993-12-20  2024-04-13  \n",
       "Area                          NaN         NaN  \n",
       "Obs                           NaN         NaN  \n",
       "Grid                          NaN         NaN  \n",
       "Alt                           NaN         NaN  \n",
       "Aspect                       -1.0    163770.0  \n",
       "Incline                      -1.0      1020.0  \n",
       "Location                      NaN         NaN  \n",
       "Air Temp                      NaN         NaN  \n",
       "Wind Dir                  -9999.0       905.0  \n",
       "Wind Speed                -9999.0       360.0  \n",
       "Cloud                     -9999.0       199.0  \n",
       "Precip Code                   NaN         NaN  \n",
       "Drift                         NaN         NaN  \n",
       "Total Snow Depth             -1.0      3000.0  \n",
       "Foot Pen                  -9999.0       310.0  \n",
       "Ski Pen                      -1.0        55.0  \n",
       "Rain at 900               -9999.0         1.0  \n",
       "Summit Air Temp             -13.4        15.0  \n",
       "Summit Wind Dir              -2.0      2213.0  \n",
       "Summit Wind Speed            -8.0       360.0  \n",
       "Observed aval. hazard         NaN         NaN  \n",
       "Forecast aval. hazard         NaN         NaN  \n",
       "Avalanche Code                NaN         NaN  \n",
       "Max Temp Grad                 0.0       130.0  \n",
       "Max Hardness Grad             0.0         5.0  \n",
       "No Settle                 -9999.0       676.0  \n",
       "Snow Index                -9999.0       368.0  \n",
       "Insolation                -9999.0       208.0  \n",
       "Crystals                  -9999.0        20.0  \n",
       "Wetness                   -9999.0        10.0  \n",
       "AV Cat                    -9999.0      8800.0  \n",
       "Snow Temp                 -9999.0       125.0  \n",
       "Comments                      NaN         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sais = pd.read_csv(\"../data/raw/SAIS_Any_snowprofiles_1993-12-20_to_2024-04-13.csv\")\n",
    "# drop last column as it's empty\n",
    "df_sais = df_sais.iloc[:, :-1]\n",
    "df_sais = df_sais.rename(columns=lambda x: x.strip())\n",
    "df_sais[\"Date\"] = pd.to_datetime(df_sais[\"Date\"], dayfirst=True)\n",
    "\n",
    "LatexHelpers.save_text_snippet(\n",
    "    f\"{len(df_sais):,}\", name=\"sais_size_initial\", path=\"../tex/assets/snippets\"\n",
    ")\n",
    "\n",
    "summary = LatexHelpers.describe(df_sais)\n",
    "\n",
    "# Convert datetime columns to date only for more succinct display\n",
    "summary.loc[\"Date\", \"mean\"] = (\n",
    "    pd.to_datetime(summary.loc[\"Date\", \"mean\"]).date()\n",
    "    if pd.notnull(summary.loc[\"Date\", \"mean\"])\n",
    "    else summary.loc[\"Date\", \"mean\"]\n",
    ")\n",
    "summary.loc[\"Date\", \"min\"] = (\n",
    "    pd.to_datetime(summary.loc[\"Date\", \"min\"]).date()\n",
    "    if pd.notnull(summary.loc[\"Date\", \"min\"])\n",
    "    else summary.loc[\"Date\", \"min\"]\n",
    ")\n",
    "summary.loc[\"Date\", \"max\"] = (\n",
    "    pd.to_datetime(summary.loc[\"Date\", \"max\"]).date()\n",
    "    if pd.notnull(summary.loc[\"Date\", \"max\"])\n",
    "    else summary.loc[\"Date\", \"max\"]\n",
    ")\n",
    "\n",
    "LatexHelpers.save_as_latex_table(\n",
    "    summary,\n",
    "    name=\"sais_summary_initial\",\n",
    "    path=\"../tex/assets/tables\",\n",
    "    caption=\"Summary of the SAIS dataset prior to any modifications\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NAs and observed avalanche hazard of \"-1\"\n",
    "n = len(df_sais)\n",
    "df_sais = df_sais.dropna(subset=[\"Forecast aval. hazard\"])\n",
    "df_sais = df_sais[df_sais[\"Forecast aval. hazard\"] != \"-1\"]\n",
    "replacements_log.loc[len(replacements_log)] = [\n",
    "    \"Forecast aval. hazard\",\n",
    "    f\"{n - len(df_sais)} missing values dropped\",\n",
    "]\n",
    "\n",
    "n = len(df_sais)\n",
    "df_sais = df_sais.dropna(subset=[\"Observed aval. hazard\"])\n",
    "df_sais = df_sais[df_sais[\"Observed aval. hazard\"] != \"-1\"]\n",
    "replacements_log.loc[len(replacements_log)] = [\n",
    "    \"Observed aval. hazard\",\n",
    "    f\"{n - len(df_sais)} missing values dropped\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LatexHelpers.save_value_count_plot(\n",
    "    df_sais,\n",
    "    \"Date\",\n",
    "    \"sais_observation_histogram\",\n",
    "    path=\"../tex/assets/figures\",\n",
    "    title_prefix=\"SAIS observations\",\n",
    ")\n",
    "\n",
    "area_summary = df_sais.groupby(\"Area\").agg(\n",
    "    total=(\"Forecast aval. hazard\", \"count\"),\n",
    "    min_date=(\"Date\", \"min\"),\n",
    "    max_date=(\"Date\", \"max\"),\n",
    ")\n",
    "area_summary[\"min_date\"] = area_summary[\"min_date\"].dt.date\n",
    "area_summary[\"max_date\"] = area_summary[\"max_date\"].dt.date\n",
    "\n",
    "LatexHelpers.save_as_latex_table(\n",
    "    area_summary,\n",
    "    f\"sais_area_breakdown\",\n",
    "    path=\"../tex/assets/tables\",\n",
    "    caption=\"Count of hazard levels and date ranges per area after dropping missing hazard values.\",\n",
    ")\n",
    "\n",
    "LatexHelpers.save_as_latex_table(\n",
    "    LatexHelpers.breakdown_per_other_column(df_sais, \"Forecast aval. hazard\", \"Area\"),\n",
    "    f\"sais_hazard_breakdown_per_area\",\n",
    "    path=\"../tex/assets/tables\",\n",
    "    caption='\"Forecast aval. hazard\" breakdown per area area after dropping missing hazard values.',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Date_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10865</th>\n",
       "      <td>2008-12-16 09:27:00</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10280</th>\n",
       "      <td>2009-10-27 14:31:00</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9693</th>\n",
       "      <td>2010-11-19 12:11:00</td>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>2011-12-08 12:20:00</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8503</th>\n",
       "      <td>2012-12-07 12:10:00</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>2013-12-12 11:37:00</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>2014-12-11 11:40:00</td>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6513</th>\n",
       "      <td>2015-12-17 10:10:00</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5778</th>\n",
       "      <td>2016-12-20 12:10:00</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>2017-12-15 11:10:00</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>2018-12-14 11:20:00</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>2019-12-13 09:40:00</td>\n",
       "      <td>243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>2020-12-02 14:35:00</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>2021-11-25 11:55:00</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>2022-12-08 10:00:00</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>2023-11-13 11:32:00</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date  Date_diff\n",
       "10865 2008-12-16 09:27:00      246.0\n",
       "10280 2009-10-27 14:31:00      193.0\n",
       "9693  2010-11-19 12:11:00      209.0\n",
       "9103  2011-12-08 12:20:00      243.0\n",
       "8503  2012-12-07 12:10:00      202.0\n",
       "7852  2013-12-12 11:37:00      214.0\n",
       "7209  2014-12-11 11:40:00      146.0\n",
       "6513  2015-12-17 10:10:00      227.0\n",
       "5778  2016-12-20 12:10:00      227.0\n",
       "5157  2017-12-15 11:10:00      256.0\n",
       "4434  2018-12-14 11:20:00      243.0\n",
       "3705  2019-12-13 09:40:00      243.0\n",
       "3095  2020-12-02 14:35:00      254.0\n",
       "2297  2021-11-25 11:55:00      200.0\n",
       "1487  2022-12-08 10:00:00      234.0\n",
       "742   2023-11-13 11:32:00      211.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# df['Date'] = pd.to_datetime(df['Date'])\n",
    "df_sais = df_sais.sort_values(by='Date')\n",
    "df_sais['Date_diff'] = df_sais['Date'].diff().dt.days\n",
    "gaps = df_sais[['Date', 'Date_diff']].sort_values(by='Date_diff', ascending=False)\n",
    "\n",
    "date_range_years = (df_sais['Date'].max() - df_sais['Date'].min()).days / 365.25\n",
    "\n",
    "\n",
    "gaps= gaps[0:round(date_range_years)].sort_values(by='Date', ascending=True)\n",
    "\n",
    "gaps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Date_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11444</th>\n",
       "      <td>2007-12-14 11:36:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>2019-03-25 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>2019-03-25 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>2019-03-26 11:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>2019-03-26 11:13:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date  Date_diff\n",
       "11444 2007-12-14 11:36:00        0.0\n",
       "3820  2019-03-25 12:00:00        0.0\n",
       "3821  2019-03-25 12:00:00        0.0\n",
       "3819  2019-03-26 11:00:00        0.0\n",
       "3818  2019-03-26 11:13:00        0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df_sais.sort_values(by='Date', ascending=True)\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "df2['Date_diff'] = df2['Date'].diff().dt.days\n",
    "gaps2 = df2[['Date', 'Date_diff']].sort_values(by='Date_diff', ascending=True)\n",
    "\n",
    "gaps2= gaps2[0:round(date_range_years)].sort_values(by='Date', ascending=True)\n",
    "\n",
    "\n",
    "gaps2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2007-12-14 10:10:00')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sais['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map hazard levels to integers\n",
    "map = lambda x: (\n",
    "    {\"low\": 1, \"mod\": 2, \"con\": 3, \"hig\": 4, \"ver\": 4}[x[:3].lower()]\n",
    "    if isinstance(x, str) and len(x) > 2\n",
    "    else None\n",
    ")\n",
    "df_sais.loc[:, \"mapped_hazard_forecast\"] = [\n",
    "    map(f) for f in df_sais.loc[:, \"Forecast aval. hazard\"]\n",
    "]\n",
    "df_sais.loc[:, \"mapped_hazard_observed\"] = [\n",
    "    map(f) for f in df_sais.loc[:, \"Observed aval. hazard\"]\n",
    "]\n",
    "\n",
    "LatexHelpers.save_as_latex_table(\n",
    "    LatexHelpers.breakdown_per_other_column(df_sais, \"mapped_hazard_forecast\", \"Area\"),\n",
    "    f\"sais_mapped_hazard_breakdown_per_area\",\n",
    "    path=\"../tex/assets/tables\",\n",
    "    caption=r'\\detokenize{\"mapped_hazard_forecast\"} breakdown per area',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sais[\"Air Temp\"] = pd.to_numeric(df_sais[\"Air Temp\"], errors=\"coerce\")\n",
    "replacements_log.loc[len(replacements_log)] = [\n",
    "    \"Air Temp\",\n",
    "    f\"Change datatype to numeric\",\n",
    "]\n",
    "\n",
    "df_sais[\"Drift\"] = pd.to_numeric(df_sais[\"Drift\"], errors=\"coerce\")\n",
    "replacements_log.loc[len(replacements_log)] = [\"Drift\", f\"Change datatype to numeric\"]\n",
    "\n",
    "\n",
    "# Set missing wind direction to 0 whenever corresoinding wind speed is 0\n",
    "df_sais.loc[\n",
    "    (df_sais[\"Summit Wind Dir\"].isna() | df_sais[\"Summit Wind Dir\"] < 0)\n",
    "    & (df_sais[\"Summit Wind Speed\"] == 0),\n",
    "    \"Summit Wind Dir\",\n",
    "] = 0\n",
    "replacements_log.loc[len(replacements_log)] = [\n",
    "    \"Summit Wind Dir\",\n",
    "    f'Set to 0 if \"Summit Wind Speed\" = 0',\n",
    "]\n",
    "df_sais.loc[\n",
    "    (df_sais[\"Wind Dir\"].isna() | df_sais[\"Wind Dir\"] < 0) & (df_sais[\"Wind Speed\"] == 0), \"Wind Dir\"\n",
    "] = 0\n",
    "replacements_log.loc[len(replacements_log)] = [\n",
    "    \"Wind Dir\",\n",
    "    f'Set to 0 if \"Wind Dir\" = 0',\n",
    "]\n",
    "\n",
    "# Use the other temperature if missing\n",
    "wh = df_sais[\"Summit Air Temp\"].isna() & df_sais[\"Air Temp\"].notna()\n",
    "df_sais.loc[wh, \"Summit Air Temp\"] = df_sais.loc[wh, \"Air Temp\"]\n",
    "wh = df_sais[\"Summit Air Temp\"].notna() & df_sais[\"Air Temp\"].isna()\n",
    "df_sais.loc[wh, \"Air Temp\"] = df_sais.loc[wh, \"Summit Air Temp\"]\n",
    "replacements_log.loc[len(replacements_log)] = [\n",
    "    \"Summit Air Temp\",\n",
    "    f'Cross fill missing values with \"Air Temp\"',\n",
    "]\n",
    "# Use other wind dir if missing\n",
    "wh = df_sais[\"Summit Wind Dir\"].isna() & df_sais[\"Wind Dir\"].notna()\n",
    "df_sais.loc[wh, \"Summit Wind Dir\"] = df_sais.loc[wh, \"Wind Dir\"]\n",
    "wh = df_sais[\"Summit Wind Dir\"].notna() & df_sais[\"Wind Dir\"].isna()\n",
    "df_sais.loc[wh, \"Wind Dir\"] = df_sais.loc[wh, \"Summit Wind Dir\"]\n",
    "replacements_log.loc[len(replacements_log)] = [\n",
    "    \"Summit Wind Dir\",\n",
    "    f'Cross fill missing values with \"Wind Dir\"',\n",
    "]\n",
    "\n",
    "# Use other wind speed if missing\n",
    "wh = df_sais[\"Summit Wind Speed\"].isna() & df_sais[\"Wind Speed\"].notna()\n",
    "df_sais.loc[wh, \"Summit Wind Speed\"] = df_sais.loc[wh, \"Wind Speed\"]\n",
    "wh = df_sais[\"Summit Wind Speed\"].notna() & df_sais[\"Wind Speed\"].isna()\n",
    "df_sais.loc[wh, \"Wind Speed\"] = df_sais.loc[wh, \"Summit Wind Speed\"]\n",
    "replacements_log.loc[len(replacements_log)] = [\n",
    "    \"Summit Wind Speed\",\n",
    "    f'Cross fill missing values with \"Wind Speed\"',\n",
    "]\n",
    "\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Precip Code\", \"0 - None\", replacements_log)\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Foot Pen\", 0, replacements_log)\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Ski Pen\", 0, replacements_log)\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Crystals\", 0, replacements_log)\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Wind Speed\", 0, replacements_log)\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Summit Wind Speed\", 0, replacements_log)\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Total Snow Depth\", 0, replacements_log)\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Max Temp Grad\", 0, replacements_log)\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Max Hardness Grad\", 0, replacements_log)\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Snow Index\", 0, replacements_log)\n",
    "LatexHelpers.fillna_and_log_value(df_sais, \"Wetness\", 0, replacements_log)\n",
    "\n",
    "df_sais[[\"precip_code_numeric\", \"precip_code_desc\"]] = df_sais[\"Precip Code\"].str.split(\n",
    "    \"-\", expand=True\n",
    ")\n",
    "df_sais[\"precip_code_numeric\"] = df_sais[\"precip_code_numeric\"].str.strip()\n",
    "df_sais[\"precip_code_numeric\"] = pd.to_numeric(df_sais[\"precip_code_numeric\"], errors=\"coerce\")\n",
    "df_sais[\"precip_code_desc\"] = df_sais[\"precip_code_desc\"].str.strip()\n",
    "replacements_log.loc[len(replacements_log)] = [\n",
    "    \"Precip Code\",\n",
    "    r'Split into \"\\detokenize{precip_code_numeric}\" and \"\\detokenize{precip_code_desc}\"',\n",
    "]\n",
    "\n",
    "df_sais = df_sais[\n",
    "    [\n",
    "        \"Date\",\n",
    "        \"Area\",\n",
    "        \"Air Temp\",\n",
    "        \"Wind Dir\",\n",
    "        \"Wind Speed\",\n",
    "        \"Cloud\",\n",
    "        \"precip_code_numeric\",\n",
    "        \"Drift\",\n",
    "        \"Total Snow Depth\",\n",
    "        \"Foot Pen\",\n",
    "        \"Ski Pen\",\n",
    "        \"Rain at 900\",\n",
    "        \"Summit Air Temp\",\n",
    "        \"Summit Wind Dir\",\n",
    "        \"Summit Wind Speed\",\n",
    "        \"Max Temp Grad\",\n",
    "        \"Max Hardness Grad\",\n",
    "        \"No Settle\",\n",
    "        \"Snow Index\",\n",
    "        \"Insolation\",\n",
    "        \"Crystals\",\n",
    "        \"Wetness\",\n",
    "        \"Snow Temp\",\n",
    "        \"mapped_hazard_forecast\",\n",
    "        \"mapped_hazard_observed\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "n = len(df_sais)\n",
    "df_sais = df_sais.dropna()\n",
    "replacements_log.loc[len(replacements_log)] = [\n",
    "    \"All columns\",\n",
    "    f\"Drop {n-len(df_sais)} with missing values\",\n",
    "]\n",
    "\n",
    "drop_rows_with_negatives = [\n",
    "    \"Wind Dir\",\n",
    "    \"Wind Speed\",\n",
    "    \"Cloud\",\n",
    "    \"Total Snow Depth\",\n",
    "    \"Foot Pen\",\n",
    "    \"Ski Pen\",\n",
    "    \"Summit Wind Dir\",\n",
    "    \"Summit Wind Speed\",\n",
    "    \"Snow Index\",\n",
    "    \"Insolation\",\n",
    "    \"Crystals\",\n",
    "    \"No Settle\",\n",
    "    \"Wetness\",\n",
    "]\n",
    "for col in drop_rows_with_negatives:\n",
    "    n = len(df_sais)\n",
    "    df_sais = df_sais[df_sais[col] >= 0]\n",
    "    replacements_log.loc[len(replacements_log)] = [\n",
    "        col,\n",
    "        f\"Drop {n-len(df_sais)} negative values\",\n",
    "    ]\n",
    "\n",
    "LatexHelpers.save_as_latex_table(\n",
    "    replacements_log,\n",
    "    \"sais_replacements_log\",\n",
    "    path=\"../tex/assets/tables\",\n",
    "    caption=\"Summary of data cleansing actions on SAIS dataset\",\n",
    "    index=False,\n",
    ")\n",
    "LatexHelpers.save_text_snippet(\n",
    "    f\"{len(df_sais):,}\", \"sais_size_final\", path=\"../tex/assets/snippets\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split df into 1 training only Area = Torridon and the remianing ones for testing\n",
    "df_test = df_sais[df_sais[\"Area\"] == \"Torridon\"]\n",
    "df_test.sort_values(by='Date').to_csv(\"../data/processed/SAIS_test.csv\", index=True)\n",
    "df_remaining = df_sais[df_sais[\"Area\"] != \"Torridon\"]\n",
    "\n",
    "LatexHelpers.save_text_snippet(\n",
    "    f\"{len(df_test):,}\", \"sais_size_test\", path=\"../tex/assets/snippets\"\n",
    ")\n",
    "\n",
    "df_train, df_dev = train_test_split(\n",
    "    df_remaining, test_size=0.2, stratify=df_remaining[[\"mapped_hazard_forecast\", \"Area\"]], random_state=1\n",
    ")\n",
    "df_train.sort_values(by='Date').to_csv(\"../data/processed/SAIS_train.csv\", index=True)\n",
    "df_dev.sort_values(by='Date').to_csv(\"../data/processed/SAIS_dev.csv\", index=True)\n",
    "\n",
    "LatexHelpers.save_as_latex_table(\n",
    "    LatexHelpers.breakdown_per_other_column(df_train, \"mapped_hazard_forecast\", \"Area\"),\n",
    "    f\"sais_mapped_hazard_breakdown_per_area_train\",\n",
    "    path=\"../tex/assets/tables\",\n",
    "    caption=r'Training set: \\detokenize{\"mapped_hazard_forecast\"} breakdown per area',\n",
    ")\n",
    "LatexHelpers.save_text_snippet(\n",
    "    f\"{len(df_test):,}\", \"sais_size_train\", path=\"../tex/assets/snippets\"\n",
    ")\n",
    "\n",
    "LatexHelpers.save_as_latex_table(\n",
    "    LatexHelpers.breakdown_per_other_column(df_dev, \"mapped_hazard_forecast\", \"Area\"),\n",
    "    f\"sais_mapped_hazard_breakdown_per_area_dev\",\n",
    "    path=\"../tex/assets/tables\",\n",
    "    caption=r'Development set: \\detokenize{\"mapped_hazard_forecast\"} breakdown per area',\n",
    ")\n",
    "LatexHelpers.save_text_snippet(\n",
    "    f\"{len(df_test):,}\", \"sais_size_dev\", path=\"../tex/assets/snippets\"\n",
    ")\n",
    "\n",
    "# create a table with mapped_hazard_forecast as rows and count of each hazard in: train, dev, test as columns\n",
    "hazard_breakdown = pd.DataFrame()\n",
    "hazard_breakdown[\"Train\"] = (\n",
    "    df_train[\"mapped_hazard_forecast\"].value_counts().sort_index()\n",
    ")\n",
    "hazard_breakdown[\"Dev\"] = df_dev[\"mapped_hazard_forecast\"].value_counts().sort_index()\n",
    "hazard_breakdown[\"Test\"] = df_test[\"mapped_hazard_forecast\"].value_counts().sort_index()\n",
    "\n",
    "hazard_breakdown.index.name = r\"\\detokenize{mapped_hazard_forecast}\"\n",
    "hazard_breakdown = hazard_breakdown.reset_index()\n",
    "\n",
    "LatexHelpers.save_as_latex_table(\n",
    "    hazard_breakdown,\n",
    "    \"sais_hazard_breakdown_per_split\",\n",
    "    path=\"../tex/assets/tables\",\n",
    "    caption=r'\\detokenize{\"mapped_hazard_forecast\"} per dataset split',\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sais['Date'] = pd.to_datetime(df_sais['Date'])\n",
    "\n",
    "num_years = df_sais['Date'].max().year - df_sais['Date'].min().year\n",
    "\n",
    "df_sais = df_sais.sort_values(by='Date')\n",
    "df_sais['Date_diff'] = df_sais['Date'].diff().dt.days \n",
    "gaps = df_sais[['Date_diff','Date']].sort_values(by='Date_diff', ascending=False)[0:num_years-1].sort_values(by='Date')\n",
    "gaps.drop(columns=['Date_diff'], inplace=True)\n",
    "\n",
    "\n",
    "season_end = gaps['Date'].apply(lambda x: df_sais[df_sais['Date'] < x]['Date'].max())\n",
    "\n",
    "gaps.loc[len(gaps)] = -1\n",
    "gaps = gaps.shift()\n",
    "gaps.iloc[0, gaps.columns.get_loc('Date')] = df_sais['Date'].min()\n",
    "\n",
    "\n",
    "gaps.rename(columns={'Date': 'season_start'}, inplace=True)\n",
    "gaps['season_end'] = season_end\n",
    "gaps.iloc[-1, gaps.columns.get_loc('season_end')] = df_sais['Date'].max()\n",
    "\n",
    "gaps['season_start'] = pd.to_datetime(pd.to_datetime(gaps['season_start']).dt.date)\n",
    "gaps['season_end'] = pd.to_datetime(pd.to_datetime(gaps['season_end']).dt.date)\n",
    "\n",
    "gaps['day_diff'] = (gaps['season_end'] - gaps['season_start']).dt.days\n",
    "\n",
    "gaps.to_csv(\"../data/aux/SAIS_seasons.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US Forest Service National Avalanche Center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/50qr5bj563lbm6jm3tks0w400000gn/T/ipykernel_14900/1716068761.py:1: DtypeWarning: Columns (0,2,5,6,9,10,14,18,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,163) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_usfs = pd.read_csv(\"../data/raw/data-1729891347683.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_usfs = pd.read_csv(\"../data/raw/data-1729891347683.csv\")\n",
    "\n",
    "\n",
    "# delete all unnamed columns\n",
    "df_usfs = df_usfs.loc[:, ~df_usfs.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "df_usfs = df_usfs.dropna(subset=[\"danger_rating\"])\n",
    "# # drop rows where danger rating is one of the above values\n",
    "df_usfs = df_usfs[\n",
    "    ~df_usfs[\"danger_rating\"].isin(\n",
    "        [\n",
    "            \"-1\",\n",
    "            \"0\",\n",
    "            \"{hac-lutak,hac-transitional,hac-chilkat-pass}\",\n",
    "            \"5\",\n",
    "            \"02/01/2024 12:27\",\n",
    "            \"13/12/2023 12:28\",\n",
    "            \"05/12/2023 12:40\",\n",
    "            -1,\n",
    "            0,\n",
    "            ' \"\"Partly Cloudy\"\"',\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "df_usfs[\"danger_rating\"] = pd.to_numeric(df_usfs[\"danger_rating\"], errors=\"coerce\")\n",
    "df_usfs = df_usfs[~df_usfs.duplicated(subset=[\"center_id\", \"start_date\", \"end_date\"], keep=\"first\")]\n",
    "len(df_usfs)\n",
    "\n",
    "summary = LatexHelpers.breakdown_per_other_column(df_usfs, \"danger_rating\", \"center_id\")\n",
    "summary[\"5\"] = summary[\"5\"].fillna(0).astype(int)\n",
    "summary.index.name = r\"\\detokenize{danger_rating}\"\n",
    "\n",
    "LatexHelpers.save_as_latex_table(\n",
    "    summary,\n",
    "    f\"usfs_hazard_breakdown_per_area\",\n",
    "    path=\"../tex/assets/tables\",\n",
    "    caption=r'US Forrestry Service dataset \\detokenize{\"danger_rating\"} breakdown per \\detokenize{\"center_id\"}',\n",
    ")\n",
    "\n",
    "LatexHelpers.save_text_snippet(\n",
    "    f\"{len(df_usfs):,}\", \"usfs_size_final\", path=\"../tex/assets/snippets\"\n",
    ")\n",
    "df_usfs.to_csv(\"../data/processed/USFS_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
